services:
  ollama:
    container_name: ollama
    entrypoint: /bin/bash
    command: >
      -c "
      set -eu
      echo 'Starting ollama serve...'
      
      ollama serve &
      OLLAMA_PID=$$!
      
      MAX_RETRIES=5
      RETRY_DELAY=2
      n=0
      
      echo 'Waiting for Ollama API...'

      for ((n=0; n<$$MAX_RETRIES; n++)); do
        if exec 3<>/dev/tcp/127.0.0.1/11434 2>/dev/null; then
          exec 3<&-
          break
        fi
        sleep $$RETRY_DELAY
      done
      
      echo 'Ollama ready. Pulling models...'
      [ -n \"$${RAG_EMBEDDING_MODEL:-}\" ] && ollama pull \"$${RAG_EMBEDDING_MODEL}\"
      [ -n \"$${RAG_CHAT_MODEL:-}\" ] && ollama pull \"$${RAG_CHAT_MODEL}\"
      
      wait $$OLLAMA_PID
      "
    image: ollama/ollama:latest
    environment:
      - OLLAMA_KEEP_ALIVE=-1  # Keep the server running indefinitely
    env_file:
      - .env
    volumes:
      - tunedd-ollama-data:/root/.ollama
    ports:
      - 11434:11434
    networks:
      - tunedd-network
    restart: on-failure

  qdrant:
    container_name: qdrant
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333"  # REST API
      - "6334:6334"  # gRPC API
    environment:
      - QDRANT__TELEMETRY_DISABLED=true
    volumes:
      - tunedd-qdrant-data:/var/lib/qdrant/data
    networks:
      - tunedd-network
    restart: on-failure

networks:
  tunedd-network:
    driver: bridge

volumes:
  tunedd-qdrant-data:
  tunedd-ollama-data:
